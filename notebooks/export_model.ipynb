{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask R-CNN - Inspect Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the work of Waleed Abdulla (Matterport)\n",
    "Modified by github.com/GustavZ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "# Model  Directory \n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_WEIGHTS = os.path.join(ROOT_DIR, \"mobile_mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS COCO Dataset\n",
    "import coco\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = os.path.join(ROOT_DIR,\"data/coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "#DEVICE = \"/cpu:0\"\n",
    "DEVICE = \"/gpu:0\"\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "#TEST_MODE = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path to trained h5 weights file\n",
    "MODEL_NAME = 'mask_rcnn_512_cocoperson_0396' # TODO: enter value here\n",
    "H5_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+\".h5\") # TODO: enter value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mmrcnn.model as modellib\n",
    "\n",
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR,config=config)\n",
    "\n",
    "# Set path to model weights\n",
    "weights_path = DEFAULT_WEIGHTS\n",
    "#weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the pb file we want to output\n",
    "MODEL_NAME = 'mask_rcnn_512_cocoperson_0396' # TODO: enter value here\n",
    "\n",
    "# Chose whether to quantize the graph\n",
    "QUANTIZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "# Get keras model and save\n",
    "model_keras= model.keras_model\n",
    "# All new operations will be in test mode from now on.\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Create output layer with customized names\n",
    "num_output = 7\n",
    "pred_node_names = [\"detections\", \"mrcnn_class\", \"mrcnn_bbox\", \"mrcnn_mask\", \"rois\", \"rpn_class\", \"rpn_bbox\"]\n",
    "pred_node_names = [\"output_\" + name for name in pred_node_names]\n",
    "pred = [tf.identity(model_keras.outputs[i], name = pred_node_names[i])for i in range(num_output)]\n",
    "\n",
    "# Get the object detection graph\n",
    "sess = K.get_session()\n",
    "if QUANTIZE:\n",
    "    # Transformations\n",
    "    transforms = [\"quantize_weights\", \"quantize_nodes\"]\n",
    "    transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [], pred_node_names, transforms)\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, transformed_graph_def, pred_node_names)\n",
    "    PB_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+'.pb') \n",
    "else:\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "    PB_MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME+'_quantized'+'.pb') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Output pb File\n",
    "graph_io.write_graph(constant_graph, \"/\", PB_MODEL_PATH, as_text=False)\n",
    "\n",
    "# Output Info\n",
    "print('{} ops in the frozen graph.'.format(len(constant_graph.node)))\n",
    "print('saved the freezed graph (ready for inference) at: ', PB_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model\n",
    "Now, we can load the model from the pb file and then use it to infere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES NOT WORK YET\n",
    "\n",
    "import cv2 \n",
    "from mmrcnn import utils\n",
    "\n",
    "utils.set_cuda_visible_devices(config.GPU_COUNT)\n",
    "with tf.device(DEVICE):\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        output_graph_def = tf.GraphDef()\n",
    "        with open(PB_MODEL_PATH, \"rb\") as f:\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "\n",
    "        image = cv2.imread(ROOT_DIR+\"/ski.jpk\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image,(config.IMAGE_MAX_DIM,config.IMAGE_MAX_DIM))\n",
    "        image = np.expand_dims(image,0)\n",
    "\n",
    "        image_resized, window, scale,_ = resize_image(image, min_dim=None, max_dim=None, padding=False)\n",
    "        image_meta = compose_image_meta(image_id=1, image_shape=image_resized.shape, window=window, active_class_ids=[0,1])\n",
    "        image_meta = np.expand_dims(image_meta,0)\n",
    "        graph = tf.get_default_graph()\n",
    "        input_image = graph.get_tensor_by_name(\"input_image:0\")\n",
    "        input_image_meta = graph.get_tensor_by_name(\"input_image_meta:0\")\n",
    "        mrcnn_mask = graph.get_tensor_by_name(\"output_mrcnn_mask:0\")\n",
    "\n",
    "        #[detections, mrcnn_class, mrcnn_bbox, mrcnn_mask,rois, rpn_class, rpn_bbox]\n",
    "        feed = {input_image:image_resized, input_image_meta:image_meta}\n",
    "        result = sess.run(mrcnn_mask, feed_dict = feed)\n",
    "        print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
